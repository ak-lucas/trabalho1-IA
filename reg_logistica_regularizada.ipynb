{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Logística com Descida de Gradiente Regularizada\n",
    "\n",
    "Este notebook foi criado para facilitar a realização dos experimentos do trabalho. Caso funcione bem, podemos adotar esta ferramenta também em trabalhos futuros.\n",
    "\n",
    "**Conteúdo do notebook: **\n",
    "\n",
    "- classe com a implementação da regressão logística com descida de gradiente regularizada;\n",
    "- main com exemplo de utilização da classe;\n",
    "- código para gerar os resultados e realizar os experimentos;\n",
    "- avaliação dos resultados;\n",
    "\n",
    "**Requisitos para executar este notebook: **\n",
    "- ter os arquivos do repositório deste notebook na mesma pasta;\n",
    "- ter numpy instalado (recomendável instalar toda pilha scipy);\n",
    "- ter sklearn instalado caso queira comparar os resultados;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classe da regressão logística com descida de gradiente regularizada:**\n",
    "\n",
    "A classe está implementada no arquivo regressao_logistica_regularizado.py que deve ser mantido no mesmo diretório deste notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**exemplo de uso**\n",
    "\n",
    "Neste exemplo é utilizada uma versão modificada do dataset iris do repositório UCI. Neste dataset uma classe foi excluída para que o dataset fosse transformado para ser utlizado em um problema de classificação binária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 100.0%\n",
      "train binary error: 0.0%\n",
      "\n",
      "test accuracy: 100.0%\n",
      "test binary error: 0.0%\n",
      "\n",
      "final loss: 0.134115529214\n"
     ]
    }
   ],
   "source": [
    "from regressao_logistica_regularizado import RegularizedLogisticRegression\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "#PREPARAÇÃO DO DATASET\n",
    "X = []\n",
    "Y = []\n",
    "with open('iris_mod.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for r in reader:\n",
    "        x = r[:-1]\n",
    "        X.append([float(a) for a in x])\n",
    "        Y.append(int(r[-1]))\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "indices = np.arange(X.shape[0])\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "X = X[indices]\n",
    "Y = Y[indices]\n",
    "\n",
    "TRAIN_SIZE = int(.8 * X.shape[0])\n",
    "\n",
    "X_train = X[:TRAIN_SIZE]\n",
    "Y_train = Y[:TRAIN_SIZE]\n",
    "\n",
    "X_test = X[TRAIN_SIZE:]\n",
    "Y_test = Y[TRAIN_SIZE:]\n",
    "\n",
    "#REGRESSÃO LOGÍSTICA\n",
    "LR = RegularizedLogisticRegression()\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "LR.fit(X_train,Y_train, epochs=epochs, learning_rate=0.08, Lambda=0.1, print_results=False)\n",
    "print(\"train accuracy: \" + str(LR.accuracy_score(X_train,Y_train)*100.0) + \"%\")\n",
    "print(\"train binary error: \" + str(LR.binary_error(X_train,Y_train)*100.0) + \"%\\n\")\n",
    "\n",
    "Y_predict = LR.predict(X_test)\n",
    "\n",
    "print('test accuracy: ' + str(LR.accuracy_score(X_test,Y_test)*100.0) + \"%\")\n",
    "print('test binary error: ' + str(LR.binary_error(X_test,Y_test)*100.0) + \"%\\n\")\n",
    "#print accuracy_score(Y_test,Y_predict)\t#sklearn accuracy\n",
    "\n",
    "print('final loss: ' + str(LR.loss[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classe para plotar gráficos**\n",
    "\n",
    "Abaixo está definida a classe utilizada para plotar gŕaficos.\n",
    "\n",
    "Parâmetros do método plot_curve:\n",
    "- X -> lista com os pontos do eixo x\n",
    "- Y -> lista com os pontos do eixo y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Plot:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def plot_curve(self, X, Y, xlabel='', ylabel='', color='blue', linewidth=2, title='', grid=False):\n",
    "        plt.plot(X, Y, color=color, linewidth=linewidth)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.title(title)\n",
    "        plt.grid(grid)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**exemplo de execução: Loss x Iteração**\n",
    "\n",
    "Abaixo está o código para plotar o gráfico da função de custo ao longo de cada iteração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nk0PBzMw6ORTMzKzT/wezhZpLpU1cggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f36077a9310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "axis_x = range(epochs+1)\n",
    "\n",
    "axis_y = LR.loss\n",
    "\n",
    "plot = Plot()\n",
    "plot.plot_curve(axis_x, axis_y, xlabel='iteracao', ylabel='loss', title='Regressao Logistica', grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Experimentos utilizando o dataset mnist\n",
    "\n",
    "Doravante assume-se que está claro como utilizar as classes que foram implementadas. Para gerar os resultados será utilizado o dataset mnist, disponibilizado para o trabalho 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estatísticas básicas do dataset\n",
    "Aqui são apresentadas as estatísticas básicas do dataset como: valor mínimo, valor máximo, média e desvio padrão de cada atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valor máximo de cada atributo:  [ 23774.  19333.  17349.  25758.]\n",
      "valor mínimo de cada atributo:  [ 2967.  3171.   926.  3957.]\n",
      "valor médio de cada atributo:  [  9570.935   8830.575   7521.04   10880.47 ]\n",
      "desvio padrão de cada atributo:  [ 3856.74613771  2549.94064527  3203.34809354  3437.92108826]\n"
     ]
    }
   ],
   "source": [
    "# carrega dataset\n",
    "X = []\n",
    "Y = []\n",
    "with open('mnist.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    c = 0\n",
    "    for r in reader:\n",
    "        if c == 1:\n",
    "            x = r[:-1]\n",
    "            X.append([float(a) for a in x])\n",
    "            Y.append(int(r[-1]))\n",
    "        c = 1\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "#print X.shape, Y.shape\n",
    "\n",
    "Max = X.max(axis=0)\n",
    "Min = X.min(axis=0)\n",
    "Mean = X.mean(axis=0)\n",
    "Std = X.std(axis=0)\n",
    "\n",
    "# axis=0 coluna / axis=1 linha\n",
    "print \"valor máximo de cada atributo: \", Max\n",
    "print \"valor mínimo de cada atributo: \", Min\n",
    "print \"valor médio de cada atributo: \", Mean\n",
    "print \"desvio padrão de cada atributo: \", Std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização dos atributos\n",
    "\n",
    "Será utilizada a normalização min-max, que é definida como:\n",
    "\n",
    "$$ \\bar{x}_j = \\frac{x_j - x^{min}_j}{x^{max}_j - x^{min}_j},$$\n",
    "\n",
    "$$ 0 \\le \\bar{x}_j \\le 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classe para normalizar dataset:**\n",
    "\n",
    "Esta classe possui um método chamado min_max que recebe um dataset e retorna um dataset com os atributos normalizados utilizando a normalização min-max. Futuramente pode-se implementar outras normalizações, como a Z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetScaling:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def min_max(self, X):\n",
    "        #print Max.shape, X.shape\n",
    "        numerator = np.subtract(X, Min)\n",
    "        denominator = np.subtract(Max, Min)\n",
    "\n",
    "        #print numerator.shape\n",
    "        #print denominator.shape\n",
    "\n",
    "        return np.divide(numerator,denominator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando o método min_max da classe DatasetScaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DatasetScaling()\n",
    "\n",
    "X_scaled = ds.min_max(X)\n",
    "#print X_scaled.shape\n",
    "#print X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
