{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste da taxa de aprendizado e número de iterações\n",
    "\n",
    "A primeira etada é ajustar a taxa de aprendizado e o número de iterações. Após alterar os outros hyperparameters (fator de regularização e grau dos atributos polinimiais) será necessário realizar o ajuste fino, mas será algum valor próximo ao encontrado nesta etapa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** imports necessários: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from regressao_logistica_regularizado import RegularizedLogisticRegression\n",
    "from experimentos import Dataset as DATASET\n",
    "from experimentos import ModelSelection\n",
    "from experimentos import Plot\n",
    "from dataset import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** varia alpha e número de iterações e plota os gráficos: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RLR = RegularizedLogisticRegression()\n",
    "MS = ModelSelection()\n",
    "DTS = DATASET()\n",
    "PLT = Plot()\n",
    "\n",
    "# carrega dataset\n",
    "X,Y = RLR.load_dataset('datasets/mnist.csv', header=True)\n",
    "\n",
    "# normaliza\n",
    "X_ =  DTS.dataset_scaling(X)\n",
    "alphas = [12, 11, 10.75, 10.5, 10.25, 10]\n",
    "epochs = [1000]\n",
    "Lambda = 0\n",
    "colors = ['red', 'blue', 'pink', 'gray', 'yellow', 'green', 'black']\n",
    "fold = 1\n",
    "errors = {}\n",
    "val_errors = {}\n",
    "loss = {}\n",
    "for train,val in MS.k_fold(X_, k=5, shuffle=True):\n",
    "    fig, ax = plt.subplots()\n",
    "    errors[str(fold)] = []\n",
    "    val_errors[str(fold)] = []\n",
    "    loss[str(fold)] = []\n",
    "    for e in epochs:\n",
    "        legends = []\n",
    "        for i,a in enumerate(alphas):\n",
    "            # ajusta o modelo\n",
    "            RLR.fit(X_[train], Y[train], X_[val], Y[val], epochs=e, learning_rate=a, Lambda=Lambda, print_results=False)\n",
    "            \n",
    "            # calcula o erro no treino\n",
    "            errors[str(fold)].append(RLR.train_error)\n",
    "            # calcula o erro no teste\n",
    "            val_errors[str(fold)].append(RLR.val_error)\n",
    "            # salva loss\n",
    "            loss[str(fold)].append(RLR.loss)\n",
    "            \n",
    "            ax.plot(range(e+1), RLR.loss, color=colors[i], linewidth=1)\n",
    "            legends.append(mpatches.Patch(color=colors[i], label='alpha = ' + str(a)))\n",
    "        #title = u'Ajuste da taxa com #epocas = ' + str(e) + ' e $\\lambda$ = ' + str(Lambda) + ' (fold ' + str(fold) + ')'\n",
    "        plt.ylim([0.1, 1])\n",
    "        plt.xlabel(u'Épocas')\n",
    "        plt.ylabel(u'Custo')\n",
    "        \n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "        box.width, box.height * 0.9])\n",
    "        ax.legend(handles=legends[:], loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=True, ncol=5)\n",
    "        #plt.title(title)\n",
    "        plt.grid(True)\n",
    "    \n",
    "        fig.savefig('fold' + str(fold) + '.eps')\n",
    "        plt.close(fig)\n",
    "        \n",
    "        #plt.show()\n",
    "        \n",
    "        fold += 1\n",
    "        \n",
    "error = []        \n",
    "val_error = []\n",
    "loss_ = []\n",
    "for k in ['1', '2', '3', '4','5']:\n",
    "    error.append(errors[k])\n",
    "    val_error.append(val_errors[k])\n",
    "    loss_.append(loss[k])\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "for i,a in enumerate(alphas):\n",
    "    mean = np.asarray(loss_).mean(axis=0)[i]\n",
    "    stdeviation = np.asarray(loss_).std(axis=0)[i]\n",
    "    print a, mean[-1], stdeviation[-1]\n",
    "    \n",
    "    ax.plot(range(epochs[0]+1), mean, color=colors[i], linewidth=1)\n",
    "    ax.fill_between(range(epochs[0]+1), mean-stdeviation, mean+stdeviation , color=colors[i], linewidth=1, alpha=0.2)\n",
    "    \n",
    "title = u'Curva de aprendizado média com #epocas = ' + str(e) + ' e $\\lambda$ = ' + str(Lambda)\n",
    "plt.ylim([0.1, 1])\n",
    "plt.xlabel(u'Épocas')\n",
    "plt.ylabel(u'Custo')\n",
    "\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "box.width, box.height * 0.9])\n",
    "lgd = ax.legend(handles=legends[:], loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=True, ncol=5)\n",
    "#plt.title(title)\n",
    "plt.grid(True)\n",
    "\n",
    "fig.savefig('media_std.png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** erro por época ** (pode ignorar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(alphas)):\n",
    "    plt.plot(range(epochs[0]+1), np.asarray(error).mean(axis=0)[i], color=colors[i], linewidth=1)\n",
    "    #legends.append(mpatches.Patch(color=colors[i], label='alpha = ' + str(a)))\n",
    "title = 'erro no treino'\n",
    "plt.ylim([0.05, 0.6])\n",
    "plt.xlabel('epocas')\n",
    "plt.ylabel('erro')\n",
    "plt.legend(handles=legends[:], loc='upper right')\n",
    "plt.title(title)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig('erro_treino.eps')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(alphas)):\n",
    "    plt.plot(range(epochs[0]+1), np.asarray(val_error).mean(axis=0)[i], color=colors[i], linewidth=1)\n",
    "    #legends.append(mpatches.Patch(color=colors[i], label='alpha = ' + str(a)))\n",
    "title = 'erro na validacao'\n",
    "plt.ylim([0.05, 0.6])\n",
    "plt.xlabel('epocas')\n",
    "plt.ylabel('erro')\n",
    "plt.legend(handles=legends[:], loc='upper right')\n",
    "plt.title(title)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig('erro_validacao.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cada linha é um alpha, cada coluna uma época e cada valor é um erro binário médio dos k-folds\n",
    "#print \"erro medio no treino \", np.asarray(error).mean(axis=0).shape\n",
    "#print \"desvio padrao no treino \", np.asarray(error).std(axis=0)\n",
    "#print \"erro medio na validacao \", np.asarray(val_error).mean(axis=0).shape\n",
    "#print \"desvio padrao na validacao \", np.asarray(val_error).std(axis=0)\n",
    "\n",
    "for i,a in enumerate(alphas):\n",
    "    print \"alpha = \", a\n",
    "    print \"erro medio final no treino \", np.asarray(error).mean(axis=0)[i][-1]\n",
    "    print \"desvio padrao final no treino \", np.asarray(error).std(axis=0)[i][-1]\n",
    "    print \"erro medio final na validacao \", np.asarray(val_error).mean(axis=0)[i][-1]\n",
    "    print \"desvio padrao final na validacao \", np.asarray(val_error).std(axis=0)[i][-1]\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva de validação: atributos polinomiais\n",
    "\n",
    "O objetivo deste experimento é analisar se a geração de atributos polinomiais trazem melhoria de\n",
    "desempenho e, mais especificamente, qual o grau de polinômio mais adequado para a tarefa. Portanto,\n",
    "deve-se variar o grau dos atributos polinomiais a partir de 1 (sem atributos polinomiais) até um valor que\n",
    "a curva de validação indique claramente que há overfitting. Neste experimento, não utilize\n",
    "regularização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 4)\n",
      "grau dos atributos polinomiais:  1\n",
      "erro médio no treino:  0.08375\n",
      "erro médio na validação:  0.095\n",
      "\n",
      "\n",
      "(200, 14)\n",
      "grau dos atributos polinomiais:  2\n",
      "erro médio no treino:  0.0875\n",
      "erro médio na validação:  0.095\n",
      "\n",
      "\n",
      "(200, 34)\n",
      "grau dos atributos polinomiais:  3\n",
      "erro médio no treino:  0.085\n",
      "erro médio na validação:  0.1\n",
      "\n",
      "\n",
      "(200, 69)\n",
      "grau dos atributos polinomiais:  4\n",
      "erro médio no treino:  0.0825\n",
      "erro médio na validação:  0.1\n",
      "\n",
      "\n",
      "(200, 125)\n",
      "grau dos atributos polinomiais:  5\n",
      "erro médio no treino:  0.085\n",
      "erro médio na validação:  0.095\n",
      "\n",
      "\n",
      "(200, 209)\n",
      "grau dos atributos polinomiais:  6\n",
      "erro médio no treino:  0.07625\n",
      "erro médio na validação:  0.105\n",
      "\n",
      "\n",
      "(200, 329)\n",
      "grau dos atributos polinomiais:  7\n",
      "erro médio no treino:  0.0775\n",
      "erro médio na validação:  0.09\n",
      "\n",
      "\n",
      "(200, 494)\n",
      "grau dos atributos polinomiais:  8\n",
      "erro médio no treino:  0.0725\n",
      "erro médio na validação:  0.095\n",
      "\n",
      "\n",
      "(200, 714)\n",
      "grau dos atributos polinomiais:  9\n",
      "erro médio no treino:  0.07875\n",
      "erro médio na validação:  0.105\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RLR = RegularizedLogisticRegression()\n",
    "MS = ModelSelection()\n",
    "DTS = DATASET()\n",
    "PLT = Plot()\n",
    "\n",
    "# carrega dataset\n",
    "X,Y = RLR.load_dataset('datasets/mnist.csv', header=True)\n",
    "\n",
    "degrees = range(1,10)\n",
    "e = 1000\n",
    "\n",
    "for d in degrees:\n",
    "    X_pol = DTS.generate_polynomial_attributes(X, d)\n",
    "    # normaliza\n",
    "    X_pol =  DTS.dataset_scaling(X_pol)\n",
    "    print X_pol.shape\n",
    "    fold = 1\n",
    "    errors = {}\n",
    "    val_errors = {}\n",
    "    loss = {}\n",
    "    for train,val in MS.k_fold(X_pol, k=5, shuffle=True):\n",
    "        errors[str(fold)] = []\n",
    "        val_errors[str(fold)] = []\n",
    "        loss[str(fold)] = []\n",
    "        legends = []\n",
    "        \n",
    "        # ajusta o modelo\n",
    "        RLR.fit(X_pol[train], Y[train], X_pol[val], Y[val], epochs=e, learning_rate=10, Lambda=0, print_results=False)\n",
    "\n",
    "        # calcula o erro no treino\n",
    "        errors[str(fold)].append(RLR.train_error[-1])\n",
    "        # calcula o erro no teste\n",
    "        val_errors[str(fold)].append(RLR.val_error[-1])\n",
    "        # salva loss\n",
    "        loss[str(fold)].append(RLR.loss)\n",
    "        #print \"erro no treino\", RLR.train_error[-1]\n",
    "        #print \"erro na validacao\", RLR.val_error[-1]\n",
    "        fold += 1\n",
    "        \n",
    "    train_error = []        \n",
    "    val_error = []\n",
    "    loss_ = []\n",
    "    for k in ['1', '2', '3', '4','5']:\n",
    "        train_error.append(errors[k])\n",
    "        val_error.append(val_errors[k])\n",
    "        loss_.append(loss[k])\n",
    "\n",
    "    print \"grau dos atributos polinomiais: \", d\n",
    "    print \"erro médio no treino: \", np.asarray(train_error).mean()\n",
    "    print \"erro médio na validação: \", np.asarray(val_error).mean()\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
